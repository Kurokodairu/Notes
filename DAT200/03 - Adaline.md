Forbedring av Perceptron: Adaline ble publisert i 1960 og anses som en forbedring av Perceptron-algoritmen
Hovedkonseptet i Adaline-algoritmen er Ã¥ definere og minimere kostnadsfunksjoner


Begge er klassifikatorer for binÃ¦r klassifisering (problemer med to klasser)
Begge har en lineÃ¦r beslutningsgrense
Begge bruker en terskelfunksjon

## Viktigste forskjeller mellom Adaline og Perceptron algoritmer:

#Perceptron:
- Vektene oppdateres ved hjelp av en trinnfunksjon ğœ™(ğ‘§) (som fungerer som en aktiveringsfunksjon)
- Feilberegningen sammenligner sanne klasseetiketter med predikerte klasseetiketter
- Oppdaterer vekter umiddelbart etter en feilklassifisering. Oppdateringer skjer flere ganger i lÃ¸pet av et fullt sett med iterasjoner (epoke)


#Adaline:
- Vektene oppdateres basert pÃ¥ en lineÃ¦r aktiveringsfunksjon ğœ™(ğ‘§)
- Den lineÃ¦re aktiveringsfunksjonen er ganske enkelt en identitetsfunksjon av nettoinngan
- Feilberegningen sammenligner sanne klasseetiketter med det kontinuerlige resultatet fra aktiveringsfunksjonen
- Oppdaterer vekter fÃ¸rst pÃ¥ slutten av hver epoke (batch-vise oppdateringer)




Objektivfunksjon: En definert objektivfunksjon (tapfunksjon, kostnadsfunksjon) er en viktig ingrediens i mange maskinlÃ¦ringsalgoritmer

. MÃ¥let er Ã¥ fange modellens ytelse ved Ã¥ beregne feilen eller avstandsscoren mellom den sanne klasseetiketten og resultatet av aktiveringsfunksjonen. Vekter beregnes slik at tapfunksjonen minimeres (finn det globale kostnadsminimumet der feilen er sÃ¥ liten som mulig)

.

Kostnadsfunksjon J: Adaline-algoritmen bruker en kostnadsfunksjon J for Ã¥ lÃ¦re vekter som Summen av kvadrerte feil (SSE) mellom resultatene (fra aktiveringsfunksjonen) og de sanne klasseetikettene

. En optimaliseringsalgoritme kalt Gradient Descent brukes til Ã¥ finne det globale minimumet av kostnadsfunksjonen J(w)



Fordel med lineÃ¦r aktiveringsfunksjon: Hovedfordelen med den lineÃ¦re aktiveringsfunksjonen over trinnfunksjonen er at kostnadsfunksjonen blir deriverbar. Dette gjÃ¸r det mulig Ã¥ utlede gradienten til tapfunksjonen, som er viktig informasjon for Ã¥ bevege seg i riktig retning mot det globale kostnadsminimumet

. SSE-kostnadsfunksjonen er konveks, noe som gjÃ¸r at gradientnedstigningsalgoritmen kan bevege seg mot vektene som resulterer i et globalt kostnadsminimum


Oppdatering av vekter med Gradient Descent: Ved hjelp av gradientnedstigning oppdateres vektene ved Ã¥ ta et skritt i motsatt retning av gradienten til kostnadsfunksjonen ğ›» (ğ‘¤)

. Vektendringen âˆ† defineres som den negative gradienten ğ›» (ğ‘¤) multiplisert med lÃ¦ringsraten. En enkelt vekt oppdateres basert pÃ¥ alle eksemplene i treningssettet (i stedet for trinnvis etter hvert eksemplar som med Perceptron-algoritmen). Dette refereres til som batch gradientnedstigning

Likhet med Perceptron: Merk likheten med vektoppdateringene til Perceptron-algoritmen: Perceptron bruker ğœ™(ğ‘§) som tar verdiene -1 eller 1, mens Adaline bruker ğœ™(ğ‘§) som tar kontinuerlige verdier ğ’˜ğ‘‡

Feature scaling: Mange maskinlÃ¦ringsalgoritmer krever en form for feature scaling (ogsÃ¥ kalt standardisering) for optimal ytelse

. Gradientnedstigning er en av algoritmene som drar nytte av feature scaling. Skalering gir dataene noen spesifikke egenskaper, som standarddistribusjon, som hjelper gradientnedstigningslÃ¦ringen til Ã¥ konvergere raskere


## Matematiske uttrykk for feature scaling:
- Feature vector: ğ’™ğ‘—
- Mean of feature vector: ğœ‡ğ‘—
- Standard deviation of feature vector: ğœğ‘—
- Scaled feature vector: ğ’™Ê¹ğ‘—
- Formula: ğ’™Ê¹ğ‘— = (ğ’™ğ‘— - ğœ‡ğ‘—) / ğœğ‘—
-
Feature scaling hjelper gradientnedstigningen (vÃ¥r optimerer) til Ã¥ finne en god eller optimal lÃ¸sning i fÃ¦rre trinn

. Merk at SSE (kostnadsfunksjon) kan forbli forskjellig fra null selv om alle prÃ¸vene ble klassifisert riktig.