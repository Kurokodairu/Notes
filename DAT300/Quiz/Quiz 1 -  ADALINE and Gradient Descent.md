# ADALINE Quiz

---
## Spørsmål 1  
**What kind of activation function does ADALINE use?**
	✅ **Riktig svar: Linear function**

> [!example]- Wrong answers
> - Sigmoid function  
> - ReLU function  

---
## Spørsmål 2  
**In the context of ADALINE, why is a bias unit incorporated into the network?**
	✅ **Riktig svar: To allow the activation function to shift left or right, facilitating more accurate function approximations.**

> [!example]- Wrong answers
> - To reduce the number of neurons required in the network.  
> - To introduce non-linearity into the network.  
> - To increase the computational speed of the network.  

---
## Spørsmål 3  
**What is a key feature of gradient descent in Adaline?**
	✅ **Riktig svar: It finds the minimum of a function**

> [!example]- Wrong answers
> - It finds the maximum of a function  
> - It increases the step size over time  

---
## Spørsmål 4  
**What is the main difference between gradient descent and stochastic gradient descent?**
	✅ **Riktig svar: Gradient descent uses all training samples for each update, while stochastic gradient descent uses one training sample per update**

> [!example]- Wrong answers
> - Stochastic gradient descent uses all training samples for each update, while gradient descent uses one training sample per update  
> - Gradient descent is only used in neural networks, while stochastic gradient descent is used in linear regression  

---
## Spørsmål 5  
**How does the learning rate affect the convergence of gradient descent?**
	✅ **Riktig svar: A very large learning rate can cause the algorithm to oscillate or even diverge.**

> [!example]- Wrong answers
> - A smaller learning rate always leads to faster convergence.  
> - The learning rate has no effect on the convergence of the gradient descent.  
